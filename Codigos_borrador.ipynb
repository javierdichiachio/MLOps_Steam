{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se agrupan por un lado todos aquellos que son de tipo \"free\"\n",
    "free_games = ['Free To Play','Free to Play','Free','Free Demo','Play for Free!','Free Mod','Free HITMAN™ Holiday Pack']\n",
    "\n",
    "# Por otro lado, se agrupa el resto de categorías:\n",
    "other_games = [valor for valor in no_floats if valor not in free_games]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los juegos gratuitos se reemplazan por cero\n",
    "df_games1['price'] = df_games1['price'].replace(no_floats, 0)\n",
    "\n",
    "# El resto de juegos se reemplaza por valores nulos\n",
    "df_games1['price'] = df_games1['price'].replace(other_games ,np.NAN)\n",
    "\n",
    "# Se convierte la columna a tipo \"float\"\n",
    "df_games1['price'] = df_games1['price'].astype(float)\n",
    "df_games1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea la función get_wordnet_pos() que nos devuelve el POS (Part of Speech) de cada palabra dentro de la review\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se instancia el lemmatizador:\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# Se cargan las stopwords:\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords = [palabra for palabra in stopwords if 'not' not in palabra]\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una lista vacía donde se almacenarán las reviews lemmatizadas \n",
    "reviews_lemma=[]\n",
    "\n",
    "for review in df_reviews[\"review\"]:\n",
    "    # Vamos a reemplzar los caracteres que no sean letras por espacios\n",
    "    review=re.sub(\"[^a-zA-Z]\",\" \",str(review))\n",
    "    # Pasamos todo a minúsculas\n",
    "    review=review.lower()\n",
    "    # Tokenizamos para separar las palabras\n",
    "    review=nltk.word_tokenize(review)\n",
    "\n",
    "    # Aplicamos el Lemmatizer (Esto puede tardar un ratito)\n",
    "    frase_lemma = [wordnet_lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in review]\n",
    "\n",
    "    # Eliminamos las palabras de menos de 3 letras\n",
    "    frase_lemma = [palabra for palabra in review if len(palabra)>3]\n",
    "    # Sacamos las Stopwords\n",
    "    review = [palabra for palabra in review if not palabra in stopwords]\n",
    "\n",
    "    # Por ultimo volvemos a unir el review\n",
    "    #review=\" \".join(review)\n",
    "    \n",
    "    reviews_lemma.append(review)\n",
    "    \n",
    "\n",
    "df_reviews[\"review_lemma\"] = reviews_lemma\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se instancia el stemmer:\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Se cargan las stopwords:\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords = [palabra for palabra in stopwords if 'not' not in palabra]\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# STEMMING\n",
    "#############################################################################\n",
    "# Se crea una lista vacía donde se almacenarán las reviews luego del stemming\n",
    "reviews_stem=[]\n",
    "\n",
    "for review in df_reviews[\"review\"]:\n",
    "    # Vamos a reemplzar los caracteres que no sean letras por espacios\n",
    "    review=re.sub(\"[^a-zA-Z]\",\" \",str(review))\n",
    "    # Pasamos todo a minúsculas\n",
    "    review=review.lower()\n",
    "    # Tokenizamos para separar las palabras\n",
    "    review=nltk.word_tokenize(review)\n",
    "    # Sacamos las Stopwords\n",
    "    review = [palabra for palabra in review if not palabra in stopwords]\n",
    "    # la funcion para buscar la raiz de las palabras\n",
    "    review = [stemmer.stem(w) for w in review]\n",
    "    # Por ultimo volvemos a unir el review\n",
    "    review=\" \".join(review)\n",
    "    # Se anexa a la lista de reviews\n",
    "    reviews_stem.append(review)\n",
    "\n",
    "# Se agrega la nueva lista de reviews al Dataframe:\n",
    "df_reviews[\"reviews_stem\"] = reviews_stem\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se aplica la funcion creada anteriormente\n",
    "df_reviews['sentiment_analysis'] = df_reviews[\"reviews_stem\"].apply(classify_sentiment)\n",
    "df_reviews.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
